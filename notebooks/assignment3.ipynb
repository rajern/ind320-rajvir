{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fccb8bb",
   "metadata": {},
   "source": [
    "# Project work, part 3 - Data quality\n",
    "\n",
    "## General\n",
    "- **<span style=\"color:red\">If you push new updates to the main branch of your GitHub repository before the peer review and teacher feedback, things will get cluttered.</span>**\n",
    "  - Create and use a new branch in the GitHub repository for new updates.  \n",
    "  - When peer review and feedback are finished, merge your changes into the main branch.\n",
    "\n",
    "- All project work in IND320 will result in personal hand-ins and online apps.  \n",
    "  1. **A Jupyter Notebook run locally on your computer.**  \n",
    "     - This will be your basic development and documentation platform.  \n",
    "       - Must include a brief description of AI usage.  \n",
    "       - Must include a 300–500-word log describing the compulsory work (including both Jupyter Notebook and Streamlit experience).  \n",
    "       - Must include links to your public GitHub repository and Streamlit app (see below) for the compulsory work.  \n",
    "     - Document headings should be clear and usable for navigation during development.  \n",
    "     - All code blocks must include enough comments to be understandable and reproducible if someone inherits your project.  \n",
    "     - All code blocks must be run before an export to PDF so the messages and plots are shown.  \n",
    "     - In addition, add the `.ipynb` file to the GitHub repository where you have your Streamlit project.  \n",
    "\n",
    "  2. **A Streamlit app running from `https://[yourproject].streamlit.app/`.**  \n",
    "     - This is an online version of the project; accessing data has been uploaded to your MongoDB database, and data directly downloaded from open-meteo.com's API.  \n",
    "     - The code, hosted at GitHub, must include relevant comments from the Jupyter Notebook and further comments regarding Streamlit usage.  \n",
    "\n",
    "- There are four parts in the project work, building on each other and resulting in a final portfolio and app to be presented at the end of the semester.  \n",
    "\n",
    "- Co-operation is applauded, and the use of AI tools is encouraged.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7f1a43",
   "metadata": {},
   "source": [
    "# Tasks\n",
    "\n",
    "### Accounts and repositories\n",
    "- Reuse your account, repository and Streamlit app from the previous part of the project work.  \n",
    "- **Until peer review and feedback have been completed, [push to a temporary GitHub branch](https://)** for later merging.\n",
    "\n",
    "### API\n",
    "- Familiarise yourself with the API connection at [https://open-meteo.com/en/docs](https://open-meteo.com/en/docs)\n",
    "  - Observe how you can select features and produce Python code.  \n",
    "  - Be aware of multiple sub-sections that alter which type of data is selected.\n",
    "\n",
    "\n",
    "## Jupyter Notebook\n",
    "\n",
    "- Use Oslo, Kristiansand, Trondheim, Tromsø and Bergen as representatives for the five electricity price areas in Norway.  \n",
    "  Find their geographical centre points in longitude and latitude.  \n",
    "  Save price area codes, city names, longitude and latitude in a Pandas DataFrame.\n",
    "\n",
    "- Use the open-meteo API to retrieve historical **reanalysis data using the ERA5 model** for a single location as follows:\n",
    "  - Create a function for the API download task that takes a pair of longitude and latitude values, plus a year as input,  \n",
    "    and downloads the same weather properties as were used in the CSV file in part 1 of the project work.  \n",
    "  - Apply the function to download data for Bergen for the year 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe2fab0",
   "metadata": {},
   "source": [
    "### Outliers and anomalies\n",
    "- Plot the temperature as a function of time.\n",
    "  - Perform a high-pass filtering of the temperature using **Direct Cosine Transfer (DCT)** to create seasonally adjusted temperature variations (SATV).\n",
    "  - Add curves to the plot indicating **Statistical Process Control (SPC)** boundaries between inliers and outliers  \n",
    "    based on the SATV according to robust statistics estimated from the whole year.  \n",
    "    Colour outliers with a contrasting colour.  \n",
    "    Do not plot SATV values; only use them to find boundaries and outliers.\n",
    "  - Let the frequency cut-off for the DCT and the number of standard deviations be parameters with sensible defaults.\n",
    "  - Wrap this in a function that returns the plot and relevant summaries of the outliers, and test the function.\n",
    "\n",
    "- Plot the precipitation as a function of time.\n",
    "  - Indicate anomalies according to the **Local Outlier Factor (LOF)** method.\n",
    "  - Let the proportion of outliers be a parameter defaulting to 1%.\n",
    "  - Wrap this in a function that returns the plot and relevant summaries of the outliers, and test the function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8faa236",
   "metadata": {},
   "source": [
    "### Seasonal-Trend decomposition using LOESS (STL)\n",
    "- Perform LOESS on the production data from *elhub* (downloaded in part 2 of the project) and plot its decomposition.\n",
    "- Let the electricity price area, production group, period length, seasonal smoother, trend smoother and robust (true/false)  \n",
    "  be parameters, and give each of them sensible defaults.\n",
    "- Wrap this in a function that returns the plot, and test the function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcb7930",
   "metadata": {},
   "source": [
    "### Spectrogram\n",
    "- Create a spectrogram based on the production data from *elhub*.\n",
    "- Let the electricity price area, production group, window length and window overlap be parameters, and give each of them sensible defaults.\n",
    "- Wrap this in a function that returns the plot, and test the function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff377aed",
   "metadata": {},
   "source": [
    "## Streamlit app\n",
    "\n",
    "- Update your Streamlit app from part 2 of the project according to the following points.\n",
    "- Move page 4 (the one with the price area selector) in front of page 2, and add a new page between page 4 and page 3,  \n",
    "  and a new page between page 3 and page 5, i.e.: Old order: 1, 2, 3, 4, 5. New order: 1, 4, new A, 2, 3, new B, 5\n",
    "\n",
    "- Exchange the CSV import of meteorological data with the **open-meteo API import**.\n",
    "- Let the choice of downloaded data depend on the selector that is now on page 2.  \n",
    "  Let the chosen year be 2021.\n",
    "- **Note:** For each of the new pages below, consider whether you can depend on the area selector on page 2 or need a local one.\n",
    "\n",
    "- On page **\"new A\"**, use `st.tabs()` and fill:\n",
    "- First tab: STL analysis  \n",
    "- Second tab: Spectrogram  \n",
    "Add necessary UI elements and plots to both.\n",
    "\n",
    "- On page **\"new B\"**, use `st.tabs()` and fill:\n",
    "- First tab: Outlier/SPC analysis  \n",
    "- Second tab: Anomaly/LOF analysis  \n",
    "Add necessary UI elements, plots and statistics to both."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
